# Sistema de Clasificaci√≥n de Documentos con ML

Sistema completo para procesar PDFs con OCR, extraer texto y entrenar modelos de clasificaci√≥n de documentos usando Machine Learning. Ideal como plantilla para proyectos similares.

## üìÅ Estructura del Proyecto

```
Modelo/
‚îú‚îÄ‚îÄ config.py                    # Configuraci√≥n centralizada
‚îú‚îÄ‚îÄ .env                         # Variables de entorno
‚îú‚îÄ‚îÄ pyproject.toml              # Dependencias (gesti√≥n con uv)
‚îú‚îÄ‚îÄ README.md                    # Este archivo
‚îÇ
‚îú‚îÄ‚îÄ scripts/                     # Scripts ejecutables
‚îÇ   ‚îú‚îÄ‚îÄ procesar_pdfs.py        # Extrae texto de PDFs (h√≠brido: OCR + texto embedido)
‚îÇ   ‚îî‚îÄ‚îÄ mover_txts.py           # Mueve TXTs a carpeta organizada
‚îÇ
‚îú‚îÄ‚îÄ entrenamiento/              # Entrenamiento del modelo ML
‚îÇ   ‚îú‚îÄ‚îÄ entrenar_modelo.ipynb   # Notebook de entrenamiento (TF-IDF + SVM)
‚îÇ   ‚îî‚îÄ‚îÄ model/                  # Modelos entrenados (generado autom√°ticamente)
‚îÇ       ‚îú‚îÄ‚îÄ ClasificadorDocumentos.pkl
‚îÇ       ‚îî‚îÄ‚îÄ info_modelo.pkl
‚îÇ
‚îî‚îÄ‚îÄ datos/                      # Datos del proyecto
    ‚îú‚îÄ‚îÄ documentos-original/    # PDFs organizados por clase
    ‚îÇ   ‚îú‚îÄ‚îÄ clase1/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ doc1.pdf
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ doc2.pdf
    ‚îÇ   ‚îú‚îÄ‚îÄ clase2/
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îÇ
    ‚îî‚îÄ‚îÄ documentos-txt/         # TXTs extra√≠dos organizados por clase
        ‚îú‚îÄ‚îÄ clase1/
        ‚îÇ   ‚îú‚îÄ‚îÄ doc1.txt
        ‚îÇ   ‚îî‚îÄ‚îÄ doc2.txt
        ‚îî‚îÄ‚îÄ clase2/
```

## üöÄ Inicio R√°pido

### 1. Instalar Dependencias

Este proyecto usa [uv](https://github.com/astral-sh/uv) para gesti√≥n de dependencias:

```powershell
# Instalar uv (si no lo tienes)
pip install uv

# Instalar dependencias del proyecto
uv sync

# Para incluir dependencias de desarrollo (Jupyter)
uv sync --extra dev
```

### 2. Configurar el Entorno

El archivo `.env` contiene todas las configuraciones. Las m√°s importantes:

```env
# Carpetas principales
DOCUMENTOS_ORIGINAL_DIR=datos/documentos-original
DOCUMENTOS_TXT_DIR=datos/documentos-txt

# OCR
OCR_USE_GPU=true          # true para GPU, false para CPU
OCR_LANG=es               # Idioma del OCR
OCR_DPI=200               # Calidad de OCR (mayor = mejor calidad, m√°s lento)

# Procesamiento
MAX_WORKERS=4             # Hilos paralelos para procesar PDFs
```

### 3. Preparar los Datos

Organiza tus PDFs por clase en `datos/documentos-original/`:

```
datos/documentos-original/
‚îú‚îÄ‚îÄ facturas/
‚îÇ   ‚îú‚îÄ‚îÄ factura001.pdf
‚îÇ   ‚îî‚îÄ‚îÄ factura002.pdf
‚îú‚îÄ‚îÄ contratos/
‚îÇ   ‚îú‚îÄ‚îÄ contrato001.pdf
‚îÇ   ‚îî‚îÄ‚îÄ contrato002.pdf
‚îî‚îÄ‚îÄ recibos/
    ‚îî‚îÄ‚îÄ recibo001.pdf
```

### 4. Procesar PDFs ‚Üí Extraer Texto

```powershell
uv run python scripts/procesar_pdfs.py
```

Esto extrae el texto de cada PDF usando:
- **Extracci√≥n directa** para p√°ginas con texto embedido
- **OCR (PaddleOCR)** para documentos escaneados o im√°genes

Los archivos `.txt` se guardan junto a los PDFs originales.

### 5. Mover TXTs a Carpeta Organizada

```powershell
uv run python scripts/mover_txts.py
```

Mueve los `.txt` a `datos/documentos-txt/` manteniendo la estructura de clases.

### 6. Entrenar el Modelo

Abre el notebook de entrenamiento:

```powershell
uv run jupyter notebook entrenamiento/entrenar_modelo.ipynb
```

O con Jupyter Lab:

```powershell
uv run jupyter lab
```

**El notebook incluye:**
- ‚úÖ Carga autom√°tica de datos desde `datos/documentos-txt/`
- ‚úÖ Divisi√≥n en train/validation/test con estratificaci√≥n
- ‚úÖ Entrenamiento con TF-IDF + SVM
- ‚úÖ Optimizaci√≥n de hiperpar√°metros con GridSearchCV
- ‚úÖ Visualizaci√≥n de m√©tricas y matriz de confusi√≥n
- ‚úÖ Guardado autom√°tico del modelo en `entrenamiento/model/`
- ‚úÖ Predicci√≥n interactiva con nuevos documentos

## üîß Configuraci√≥n Avanzada

### Par√°metros de OCR

Edita `.env` para ajustar el comportamiento del OCR:

```env
# Confianza m√≠nima para aceptar texto OCR (0.0 - 1.0)
OCR_CONFIDENCE_THRESHOLD=0.5

# DPI para OCR de alta calidad
OCR_DPI_HIGH_QUALITY=250

# Umbral para detectar im√°genes que requieren OCR (p√≠xeles)
IMAGE_PIXEL_THRESHOLD=200000

# Caracteres m√≠nimos para considerar texto embedido
TEXT_CHAR_THRESHOLD=100
```

### Limpieza de Texto

El sistema elimina autom√°ticamente firmas digitales y c√≥digos de verificaci√≥n:

```env
LIMPIAR_FIRMAS_DIGITALES=true
LIMPIAR_CODIGOS_VERIFICACION=true
```

## üìä Flujo de Trabajo Completo

```
1. Organizar PDFs por clase
   ‚îî‚îÄ> datos/documentos-original/clase1/*.pdf

2. Extraer texto
   ‚îî‚îÄ> python scripts/procesar_pdfs.py
       ‚îî‚îÄ> Genera *.txt junto a cada PDF

3. Mover TXTs
   ‚îî‚îÄ> python scripts/mover_txts.py
       ‚îî‚îÄ> datos/documentos-txt/clase1/*.txt

4. Entrenar modelo
   ‚îî‚îÄ> Ejecutar notebook: entrenar_modelo.ipynb
       ‚îî‚îÄ> Genera modelo en entrenamiento/model/

5. Predecir nuevos documentos
   ‚îî‚îÄ> Usar √∫ltima celda del notebook
```

## üéØ Usar Como Plantilla

Para adaptar este proyecto a un nuevo conjunto de datos:

1. **Limpiar datos anteriores:**
   ```powershell
   Remove-Item -Recurse datos/documentos-original/*
   Remove-Item -Recurse datos/documentos-txt/*
   Remove-Item -Recurse entrenamiento/model/*
   ```

2. **Agregar nuevos PDFs** en `datos/documentos-original/`, organizados por clase

3. **Seguir el flujo de trabajo** desde el paso 2

4. **Ajustar configuraci√≥n** en `.env` si es necesario (OCR, DPI, etc.)

## üõ†Ô∏è Comandos √ötiles

```powershell
# Ver configuraci√≥n actual
uv run python config.py

# Instalar solo dependencias base (sin dev)
uv sync --no-dev

# Actualizar dependencias
uv sync --upgrade

# Ejecutar scripts
uv run python scripts/procesar_pdfs.py
uv run python scripts/mover_txts.py

# Jupyter
uv run jupyter notebook
uv run jupyter lab
```

## üìù Notas T√©cnicas

### OCR con PaddleOCR

- **GPU**: Requiere CUDA 11.x instalado
- **CPU**: Funciona sin CUDA pero m√°s lento
- **Idiomas**: Configurable en `.env` (`OCR_LANG=es`)

### Procesamiento H√≠brido

El script `procesar_pdfs.py` detecta autom√°ticamente:
- P√°ginas escaneadas ‚Üí usa OCR
- P√°ginas con texto embedido ‚Üí extracci√≥n directa
- Ahorra tiempo procesando solo lo necesario

### Modelo ML

- **Algoritmo**: TF-IDF + SVM lineal
- **Optimizaci√≥n**: GridSearchCV con validaci√≥n cruzada
- **M√©tricas**: Accuracy, F1-macro, matriz de confusi√≥n
- **Formato**: Guardado con `joblib` (`.pkl`)

## ‚ö†Ô∏è Soluci√≥n de Problemas

### Error: "No se encontraron PDFs"

Verifica que los PDFs est√©n en `datos/documentos-original/clase1/`, no en la ra√≠z.

### Error: "Modelo no existe"

Ejecuta el notebook de entrenamiento completo antes de intentar predicciones.

### OCR muy lento

- Reduce `OCR_DPI` en `.env` (ej: 150)
- Reduce `MAX_WORKERS` si tienes poca RAM

### Error de CUDA/GPU

Si PaddleOCR da error con GPU:
```env
OCR_USE_GPU=false
```

## üì¶ Dependencias Principales

- **PaddleOCR**: OCR con deep learning
- **scikit-learn**: Modelo de clasificaci√≥n (TF-IDF + SVM)
- **PyMuPDF**: Procesamiento de PDFs
- **OpenCV**: Procesamiento de im√°genes
- **pandas**: Manipulaci√≥n de datos
- **joblib**: Persistencia del modelo

